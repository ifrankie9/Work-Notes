## Task Today ##
- [x] Re-play [SQL](https://courses.edx.org/courses/course-v1:Microsoft+DAT201x+1T2018a/progress)
  - Lab 9,10
- [ ] Reviewing ISYE6501 HW2  

```
**********************************************************************************
*********************       K-means Clustering    ********************************
**********************************************************************************

# table() uses the cross-classifying factors 
# to build a contingency table of the counts at each combination of factor levels.
table(data[,5], data$Species)

# -------------------------- Visualizing Data -------------------------------------
# library ggplot2 provides a powerful model of graphics 
# that makes it easy to produce complex multi-layered graphics.
library(ggplot2)
ggplot(data, aes(Petal.Length, Petal.Width, color=Species)) + geom_point()
ggplot(data, aes(Sepal.Length, Sepal.Width, color=Species)) + geom_point()

# -------------------------- Performing the kmeans clustering ---------------------
# using all attributes with k=3, 20 different random starting assignments and
# select the one with the lowest within cluster variation
irisClusterAll3 <- kmeans(data[,1:4], 3, nstart=20)

# This is how we'd get Lloyd's algorithm:
# irisClusterALL2lloyd <- kmeans(iris[,1:4], 2, algorithm="Lloyd", nstart = 20)

# scale data !!!!!!!
scdata <- data
for (i in 1:4) { scdata[,i] <- (data[,i]-min(data[,i])) / (max(data[,i])-min(data[,i])) }
irisClusterscAll3 <- kmeans(scdata[,1:4], 3, nstart=20)

# initial distance to zero
csum = 0

# for each data point
for (i in 1:nrow(data)) {
    # add distance between its point and its cluster center
    csum = csum + dist(rbind(data[i,1:4], irsiClusterAll3$centers[irisClusterAll3$cluster[i],]))
}

table(irisClusterALL3$cluster, data$Species)
table(irisClusterALLsc3$cluster, data$Species)
```
