## Task Today ##

- [x] Reviewing ISYE6501 WEEK6 
   ### Missing Data (C) 
   #### Dealing with missing data
     - Throw away
     - Use categorical variables to indicate missing data
       - Add category variable: missing
       - All missing data: 0
       - include interactions variables between the categorical variable and other variables
     - Estimate missing values
   #### Imputation Methods: estimate the missing data (trade off, simplicity, realism)
     - Midrange value (mean, median[numeric] or mode[categorical])
       - Advantage: hedge against being too wrong, easy to compute
       - Disadvantage: Biased imputation
     - Regression: reduce or eliminate the problem of bias
       - Disadvantage: Complex(build, fit, validate, test to estimate missing data), does not capture all the variability
     - Impute with added variability (Add perturbation 扰动 to each imputed value)
       - No perturbation: More accurate on average, less accurate variability
       - Perturbation distributed: Less accurate on average, more accurate variability
     - Notes: 1. Limit the amount of imputation you do, no more than 5% per factor
   #### Optimization for predictive analytics
     - Used for: descriptive描述性 / predictive预测性 / prescriptive规定性 analytics
     - Notes: Statistical software can both build and solve regression models. Optimization software only solves models; human experts are required to build optimization models
     - Optimization Models:
       - Three main components: 
         - Variables : decisions to made - find best combinations of variables
         - Constraints: restrictions on variable values 
         - Objective function: solution quality measure
         ***
         - Solution: values for each variable
         - Feasible solution: variable values that satisfy all constraints
         - Optimal solution: feasible solution with the best objective value
       - In order to use the optimization model, we first need to use statistical methods, like regression, to find the right values of alpha and beta, to determine the relationship between time and votes, etc.
       
- [x] ISYE6501 WEEK6 HW6
 ```
#################### Mean/Mode Imputation ####################
mode_V7 <- as.numeric(getmode(data[-missing,"V7"]))

# Impute V7 for observations with missing data for V7 to mode_V7.
data_mode_imp <- data
data_mode_imp[missing,]$V7 <- mode_V7
data_mode_imp$V7 <- as.integer(data_mode_imp$V7)

#################### Regression Imputation ####################
# Generate linear model using all other factors as predictors
model <- lm(V7~V2+V3+V4+V5+V6+V8+V9+V10, data = data_modified)
summary(model)

# Not all predictors are significant, so use backwards stepwise
# regression for variable selection.
step(model)

# Use cross-validation to test how good this model really is.
library(DAAG)
model_cv <- cv.lm(data_modified, model2, m=5)
SST <- sum((as.numeric(data[-missing,]$V7) - mean(as.numeric(data[-missing,]$V7)))^2)
R2_cv <- 1 - attr(model_cv,"ms")*nrow(data[-missing,])/SST

# Get predictions for missing V7 values.
V7_hat <- predict(model2, newdata = data[missing,])

# Impute V7 for observations with missing data for V7 to predicted values with this linear model.
data_reg_imp <- data
data_reg_imp[missing,]$V7 <- V7_hat
data_reg_imp$V7 <- as.numeric(data_reg_imp$V7)

# Make sure no V7 values are outside of the orignal range
data_reg_imp$V7[data_reg_imp$V7 > 10] <- 10
data_reg_imp$V7[data_reg_imp$V7 < 1] <- 1

#################### Regression with Perturbation Imputation ####################
# Perturb the predictions for missing V7 values with a random normal distriubtion in which the
# predicted values are the means and the standard deviation is the standard deviation of the predicted values.
V7_hat_pert <- rnorm(nrow(data[missing,]), V7_hat, sd(V7_hat))

data_reg_pert_imp <- data
data_reg_pert_imp[missing,]$V7 <- V7_hat_pert
data_reg_pert_imp$V7 <- as.numeric(data_reg_pert_imp$V7)
 ```
