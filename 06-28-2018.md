## Task Today ##

- [x] Reviewing ISYE6501 WEEK7 
   ### Optimization (2) 
   #### Optimization for Statistical Models (statistical models have underlying optimization models)
     - <b>Linear Regression Model</b>
       - Given *n* data points, *x*ij=*j*th factor for data point *i*, *y*i=response for data point *i*
       - Variables: *a*0, *a*1, *a*2, ..., *a*m
       - Constraint: None
       - Objective function: Minimize n∑(*i*=1) [*y*i-(*a*0 + m∑(*j*=1)*a*j*x*ij)]²
       - NOTE!: 和Optimization view正好相反, Statistical point of view, [*a*0, *a*j, constant coefficients], x*ij are variables 
       - Lasso regression Constraint,  Minimize m∑(*j*=1) |*a*j| <= T
       - Ridge regresison Constraint,  Minimize m∑(*j*=1) (*a*j)² <= T
       - Elastic net regression Constraint,  λ Minimize m∑(*j*=1) |*a*j| + (1-λ) Minimize m∑(*j*=1) (*a*j)² <= T
     - <b>Logistic Regression Model</b>
       - Given *n* data points, *x*ij=*j*th factor for data point *i*, *y*i=response for data point *i*
       - Variables: *a*0, *a*1, *a*2, ..., *a*m
       - Constraint: None
       - Objective function: Maximize *i*∑(*yi*=1)*p*(*x*) *i*∑(*yi*=0)(1 - *p*(*x*)) where *p*(*xi*) = 1/(1+e-(a0+m∑(*j*=1)*a*j *x*ij)) 
     - <b>Hard Classification</b>
       - Variables: *a*0, *a*1, *a*2, ..., *a*m
       - Constraint: (a0+m∑(*j*=1)*a*j *x*ij)*y*i >= 1 for each *i*
       - Objective function: Maximize m∑(*j*=1) (*a*j)²
     - <b>Soft Classification</b>
       - Variables: *a*0, *a*1, *a*2, ..., *a*m
       - Constraint: None
       - Objective function: Minimize m∑(*i*=1) max{0,1 - (a0+m∑(*j*=1)*a*j *x*ij)*y*i } + λ m∑(*j*=1) (*a*j)²
     - <b>Exponential Smoothing -- Time Series Models</b>
       - Variables: α, β, γ
       - Constraint: (a0+m∑(*j*=1)*a*j *x*ij)*y*i >= 1 for each *i*
       - Objective function: Minimize n∑(*t*=1)(xt - x_hat t)²
     - <b>ARIMA -- Time Series Models</b>
       - Variables: μ, φi, θi
       - Constraint: None
       - Objective function: Minimize n∑(*t*=1)(xt - x_hat t)² where D(d)t = μ + p∑(*i*=1)αi D(d)t-i - q∑(*i*=1)αθi (x_hat t-i - x t-i)
     - <b>K-Means for clustering Model</b>
       - Given *x*ij=coordinate *j* of data point *i* (value of jth attribute of data point *i*)
       - Variables: Zjk (coordinate *j* of cluster center *k*), yik(1 if point i in cluster k, 0 if not)
       - Constraint: ∑k yik = 1 for all data point *i* (each data point assigned to a cluster)
       - Objective function: Minimize ∑*i*∑*k* yik p-root-square[(∑*j* ((*x*ij-zjk))p-square)]
   #### Classification of Optimization Models
     - <b>Linear Regression Model</b>
       - f(x) is a linear funciton, Minimize or Maximize C + n∑(*i*=1)CiXi
       - Constraint set X is defined by linear equation and inequalities
       - Easy/fast to solve, even for very large instances
     - <b>Convex Quadratic Program 凸二次方程</b>
       - f(x) is a convex quadratic function, Minimize f(x) or Maximize -f(x)
       - Constraint set X is defined by linear equation and inequalities
       - Easy/fast to solve, but not as quickly as linear programs
     - <b>Convex Optimization Program</b>
       - f(x) is a Convex (if minimizing), Concave (if maximizing)
       - Constraint set X is a convex set
       - Easy/fast to solve, but solutions can take a lot longer
     - SUMMARY: From quickest/easiest to slowest/hardest
         1. Linear Programs
         2. Convex Quadratic Programs
         3. Convex Programs
         4. Integer Programs
         5. General Non-Convex Programs
     - Network Optimization Models (type of linear program but solved even faster)
       - i, location/node/vertex
       - Line, Connection/arc/edge
       - xij, variable for arc from i to j (how much flow there is)
       - Constraints: flow into node = flow out of node, flow on arc between min and mx allowable
       - Objective function: Linear funcion of variable. (if all data is integer, them all optimal variable values will automatically be integer too!) 
   #### Stochastic随机 Optimization
     - Model Conservatively保守
     - 前面的Optimization模型，一类知道需要的input data，一类知道预计的output结果，但在实际生活中存在，不清楚需要的数据，也不知道预计的结果, 这时需要增加随便变量，使系统稳定
     - <b>Dynamic Program</b>
       - States (the exact situations, and their values)
       - Decisions (choice of next state)
       - Bellman's equation: determine optimal decisions
     - <b>Stochastic Dynamic Program</b>
       - Dynamic program, but decisions have probabilities of next state
     - <b>Markov Decision process</b>
       - Stochastic dynamic program with Discrete states and decisions
       - Probabilities depend only on current state/decision
   #### Basic Optimization Algorithms
     - Different types of optimization models are solved using different algorithms, most has two main steps:
       - Create a first solution (can be simple/bad/infeasible)
       - Repeat
         - Find an improving direction t
         - Using a step size Θ to move along it
         - New solution = old solution + Θt
       - Stop when solution doesn't change much or time runs out
     - Guanranteed to find optimal solution : Convex Optimization
     - Not Guanranteed to find optimal solution: Non-Convex Optimization 

